Encoding Categorical Variables
70
Here, the numerator is the sum of the target across observations in category i and â€‹nâ€‹â€¯iâ€‹ is the total number 
of observations in category i.
These formulas provide a good approximation of the target estimate if there is a sufficiently large 
number of observations with each category value â€“ in other words, if â€‹nâ€‹â€¯iâ€‹ is large. However, in many 
datasets, there will be categories present in a few observations. In these cases, target estimates derived 
from the precedent formulas can be unreliable.
To mitigate poor estimates returned for rare categories, the target estimates can be determined as a 
mixture of two probabilities: those returned by the preceding formulas and the prior probability of 
the target based on the entire training. The two probabilities are blended using a weighting factor, 
which is a function of the category group size:
â€‹Sâ€‹â€¯iâ€‹â€…= Î»â€‰â€‹â€¯
â€‹nâ€‹â€¯iâ€‹(â€‹Y=1â€‹)â€‹â€‹â€¯
_â€¯
â€‹nâ€‹â€¯iâ€‹â€¯ â€‹â€…+â€…â€‹(â€‹1â€…âˆ’â€…â€‹Î»â€‹â€¯iâ€‹)â€‹â€‰â€‹â€¯
â€‹nâ€‹â€¯Î»â€‹â€¯
_â€¯
Nâ€¯â€‹
In this formula, â€‹nâ€‹â€¯Î»â€‹ is the total number of cases where the target takes a value of 1, N is the size of the 
train set, and ğœ† is the weighting factor.
When the category group is large, ğœ† tends to 1, so more weight is given to the first term of the equation. 
When the category group size is small, then ğœ† tends to 0, so the estimate is mostly driven by the second 
term of the equation â€“ that is, the targetâ€™s prior probability. In other words, if the group size is small, 
knowing the value of the category does not tell us anything about the value of the target.
The weighting factor, ğœ†, is determined differently in different open-source implementations. In Category 
Encoders, ğœ† is a function of the group size, k, and a smoothing parameter, f, which controls the rate 
of transition between the first and second term of the preceding equation:
â€‹Î»â€…= â€‹â€¯
1â€¯
_â€¯
1+ â€‹eâ€‹â€¯â€‹âˆ’â€‹(â€‹nâˆ’kâ€‹)â€‹/fâ€‹â€¯â€‹
Here, k is half of the minimal size for which we fully trust the first term of the equation. The f parameter 
is selected by the user either arbitrarily or with optimization.
In scikit-learn and feature-engine, ğœ† is a function of the target variance for the entire 
dataset and within the category, and is determined as follows:
â€‹Î»â€…= â€‹â€¯ ni Ã—â€…tâ€¯
_â€¯
sâ€…+â€…ni Ã—â€…tâ€¯â€‹
Here, t is the target variance in the entire dataset and s is the target variance within the category. Both 
implementations are equivalent, but it is important to know the equations because they will help you 
set up the parameters in the transformers.
Note
Mean encoding was designed to encode highly cardinal categorical variables without expanding 
the feature space. For more details, check out the following article: Micci-Barreca D. A., 
Preprocessing Scheme for High-Cardinality Categorical Attributes in Classification and Prediction 
Problems. ACM SIGKDD Explorations Newsletter, 2001.
