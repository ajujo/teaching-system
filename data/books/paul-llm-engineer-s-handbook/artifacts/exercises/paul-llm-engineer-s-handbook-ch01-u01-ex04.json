{
  "$schema": "exercise_set_v1",
  "exercise_set_id": "paul-llm-engineer-s-handbook-ch01-u01-ex04",
  "unit_id": "paul-llm-engineer-s-handbook-ch01-u01",
  "book_id": "paul-llm-engineer-s-handbook",
  "provider": "lmstudio",
  "model": "qwen3-32b",
  "difficulty": "mid",
  "types": [
    "quiz"
  ],
  "generation_time_ms": 100720,
  "mode": "json",
  "pages_used": [
    10,
    11,
    12,
    13,
    14,
    15,
    16,
    17,
    18
  ],
  "created_at": "2026-02-02T17:33:00.823892+00:00",
  "total_points": 6,
  "passing_threshold": 0.7,
  "exercises": [
    {
      "exercise_id": "paul-llm-engineer-s-handbook-ch01-u01-ex04-q01",
      "type": "multiple_choice",
      "difficulty": "medium",
      "question": "¿Cuál de las siguientes opciones describe correctamente una ventaja principal del enfoque FTI (Feature-Training-Inference) mencionado en la página 15?",
      "correct_answer": 1,
      "explanation": "El enfoque FTI permite compartir componentes entre los pipelines de feature, training e inference, lo que mejora la coherencia y reduce el esfuerzo de mantenimiento. Esto se menciona explícitamente como uno de los beneficios clave del diseño (página 15).",
      "points": 1,
      "tags": [
        "FTI Architecture",
        "ML Systems"
      ],
      "options": [
        "Reduce el costo computacional al eliminar los modelos preentrenados.",
        "Permite compartir componentes entre los tres pipelines, facilitando la coherencia y mantenimiento.",
        "Simplifica el proceso de entrenamiento al ignorar la etapa de inferencia.",
        "Aumenta la latencia en sistemas de producción mediante la duplicación de datos."
      ]
    },
    {
      "exercise_id": "paul-llm-engineer-s-handbook-ch01-u01-ex04-q02",
      "type": "true_false",
      "difficulty": "medium",
      "question": "Según la página 7, el MVP de un LLM Twin debe incluir todas las funcionalidades potenciales del producto final.",
      "correct_answer": false,
      "explanation": "El MVP (Minimum Viable Product) se define como la versión más simple que resuelve el problema fundamental y permite validar la hipótesis del negocio. Incluir todas las funcionalidades no es necesario ni recomendable en esta fase temprana.",
      "points": 1,
      "tags": [
        "MVP",
        "LLM Twin"
      ]
    },
    {
      "exercise_id": "paul-llm-engineer-s-handbook-ch01-u01-ex04-q03",
      "type": "short_answer",
      "difficulty": "hard",
      "question": "Explique, basándose en la página 8, por qué los sistemas de ML tradicionales suelen fallar sin un enfoque estructurado como el FTI.",
      "correct_answer": "Los sistemas de ML tradicionales suelen fallar porque no manejan adecuadamente la complejidad del flujo de datos entre preprocesamiento, entrenamiento e inferencia. Esto genera inconsistencias y dificultades para escalar o mantener el sistema a largo plazo.",
      "explanation": "La página 8 destaca que los sistemas ML tradicionales carecen de una estructura clara para separar y conectar las etapas críticas, lo que lleva a problemas de mantenibilidad y escalabilidad. El enfoque FTI aborda estos desafíos mediante pipelines especializados.",
      "points": 2,
      "tags": [
        "ML Systems",
        "FTI Architecture"
      ]
    },
    {
      "exercise_id": "paul-llm-engineer-s-handbook-ch01-u01-ex04-q04",
      "type": "multiple_choice",
      "difficulty": "medium",
      "question": "¿Cuál de las siguientes razones justifica el uso de un LLM Twin en lugar de un chatbot genérico como ChatGPT, según la página 5?",
      "correct_answer": 1,
      "explanation": "La página 5 explica que los LLM Twin se diseñan para casos de uso empresariales específicos, permitiendo personalizar el modelo con datos del dominio y optimizar su arquitectura. Esto contrasta con soluciones genéricas como ChatGPT.",
      "points": 1,
      "tags": [
        "LLM Twin",
        "Chatbots"
      ],
      "options": [
        "Los chatbots genéricos no pueden manejar consultas técnicas avanzadas.",
        "Un LLM Twin permite personalizar el modelo con datos específicos del dominio y optimizar su arquitectura para casos de uso empresariales.",
        "ChatGPT carece de soporte para lenguajes de programación modernos como Python o JavaScript.",
        "Los chatbots genéricos no son compatibles con frameworks de ML como Hugging Face."
      ]
    },
    {
      "exercise_id": "paul-llm-engineer-s-handbook-ch01-u01-ex04-q05",
      "type": "true_false",
      "difficulty": "medium",
      "question": "En la página 17, se afirma que el diseño de la arquitectura del LLM Twin usando pipelines FTI no requiere considerar la interacción entre los tres componentes (feature, training e inference).",
      "correct_answer": false,
      "explanation": "La página 17 indica explícitamente que el diseño debe integrar los tres pipelines (feature, training e inference) para garantizar coherencia y eficiencia en la arquitectura. Ignorar esta interacción llevaría a sistemas ineficaces.",
      "points": 1,
      "tags": [
        "LLM Twin Architecture",
        "FTI Design"
      ]
    }
  ]
}