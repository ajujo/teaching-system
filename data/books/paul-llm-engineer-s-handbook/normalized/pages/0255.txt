Supervised Fine-Tuning
224
        bf16=is_bfloat16_supported(),
        logging_steps=1,
        optim="adamw_8bit",
        weight_decay=0.01,
        warmup_steps=10,
        output_dir="output",
        report_to="comet_ml",
        seed=0,
    ),
)
trainer.train()
Training this model on our concatenated dataset can take a few hours. For example, it
takes 50 minutes on an A100 GPU.
10.	 Once it's done, we can test it with a quick example. The goal is not to properly evaluate
the fine-tuned model, but to make sure that there are no obvious errors related to the
tokenizer or chat template.
For fast inference, we can use FastLanguageModel.for_inference() from Unsloth. We
directly format an instruction with the Alpaca format. Note that we provide an empty
answer to append the assistant header (### Response): at the end of the user instruction.
This forces the model to answer the instruction instead of completing it. We also use a text
streamer to stream the generation instead of waiting for it to be complete before printing it.
FastLanguageModel.for_inference(model)
message = alpaca_prompt.format("Write a paragraph to introduce
supervised fine-tuning.", "")
inputs = tokenizer([message], return_tensors="pt").to("cuda")
text_streamer = TextStreamer(tokenizer)
_ = model.generate(**inputs, streamer=text_streamer, max_new_
tokens=256, use_cache=True)
11.	 Here is the answer provided by our model:
Supervised fine-tuning is a method used to enhance a language model
by providing it with a curated dataset of instructions and their
corresponding answers. This process is designed to align the model's
