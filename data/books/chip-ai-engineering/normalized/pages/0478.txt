AFINADO DE TAREAS ESPECÍFICAS DE DOMINIO
Hay que tener cuidado con el argumento de que los modelos de uso
general no funcionan bien para tareas específicas de dominio y, por lo
tanto, hay que afiinar o entrenar modelos para sus tareas específicas. A
medida que los modelos de propósito general se vuelven más capaces,
también mejoran en las tareas específicas de dominio y pueden superar
a los modelos específicos de dominio.
Un modelo especializado temprano interesante es BloombergGPT, que
fue introducido por Bloomberg en marzo de 2023. Los modelos más
potentes del mercado por entonces eran todos patentados, y Bloomberg
quería un modelo de tamaño medio que funcionara bien en tareas
financieras y pudiera alojarse internamente para casos de uso con datos
confidenciales. El modelo, con 50 000 millones de parámetros, necesitó
1.3 millones de horas de GPU A100 para su entrenamiento. El costo
estimado del cálculo fue de entre 1.3 y 2.6 millones de dólares, sin
contar el costo de los datos (Wu et al., 2023).
Ese mismo mes, OpenAI lanzó GPT-4-0314. 4 La investigación de Li et
al. (2023) demostró que el GPT-4-0314 superaba significativamente a
BloombergGPT en varias pruebas comparativas financieras. En la
Tabla 7-1 se detallan dos de estos pruebas comparativas.
tabla 7-1. Los modelos de propósito general como GPT-4 pueden
superar a los modelos financieros en los dominios financieros.
Modelo
Análisis de
sentimientos FiQA
(F1 ponderado)
ConvFinQA
(precisión)
GPT-4-0314 (cero
shots)
87.15
76.48
BloombergGPT
75.07
43.41
