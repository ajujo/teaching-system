figura 5-11. PAIR utiliza una IA atacante para generar prompts para eludir las
restricciones de la IA objetivo. Imagen de Chao et al. (2023). Esta imagen est치 bajo
licencia CC BY 4.0.
En su experimento, PAIR a menudo requiere menos de veinte consultas
para producir un jailbreak
Inyecci칩n indirecta de prompts
La inyecci칩n indirecta de prompts es una forma nueva y mucho m치s potente
de realizar ataques. En vez de colocar instrucciones maliciosas en el prompt
directamente, los atacantes colocan estas instrucciones en las herramientas
con las que se integra el modelo. La Figura 5-12 muestra el aspecto de este
ataque.
