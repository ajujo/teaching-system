cuantización y la destilación. La cuantización, es decir, la reducción de la
precisión de un modelo para reducir su huella de memoria y aumentar su
throughput, se analiza en el Capítulo 7. La destilación de modelos, que
consiste en entrenar un modelo pequeño para que imite el comportamiento
del modelo grande, se aborda en el Capítulo 8.
La destilación de modelos sugiere que es posible capturar los
comportamientos de un modelo grande utilizando menos parámetros.
¿Podría ser que dentro del modelo grande existiera un subconjunto de
parámetros capaz de captar el comportamiento de todo el modelo? Este es
el concepto básico de la poda.
La poda, en el contexto de las redes neuronales, tiene dos significados. Uno
es eliminar nodos enteros de una red neuronal, lo que significa cambiar su
arquitectura y reducir su número de parámetros. Otro es encontrar los
parámetros menos útiles para las predicciones y ponerlos a cero. En este
caso, la poda no reduce el número total de parámetros, sino solo el número
de parámetros distintos de cero. Esto hace que el modelo sea más disperso,
lo que reduce el espacio de almacenamiento del modelo y acelera el cálculo.
Los modelos podados pueden utilizarse tal cual o afinarse aún más para
ajustar los parámetros restantes y restaurar cualquier degradación del
rendimiento causada por el proceso de poda. La poda puede ayudar a
descubrir arquitecturas de modelo prometedoras (Liu et al., 2018). Estas
arquitecturas podadas, más pequeñas que las pre-podadas, también pueden
entrenarse desde cero (Zhu et al., 2017).
En la literatura se han publicado muchos resultados alentadores sobre la
poda. Por ejemplo, Frankle y Carbin (2019) demostraron que las técnicas de
poda pueden reducir en más del 90 % los recuentos de parámetros distintos
de cero de ciertas redes entrenadas, disminuyendo las huellas de memoria y
mejorando la velocidad sin poner en riesgo la precisión. Sin embargo, en la
práctica, en el momento de escribir este artículo la poda es menos común.
Es más difícil de hacer, ya que requiere una comprensión de la arquitectura
del modelo original, y el aumento de rendimiento que puede aportar suele
ser mucho menor que el de otros enfoques. La poda también da lugar a
modelos dispersos, y no todas las arquitecturas de hardware están diseñadas
para aprovechar la dispersión resultante.
