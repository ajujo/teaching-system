• There's a clear evaluation rubric or checklist (e.g., correctness, completeness,
tone).
• The cost of generating additional outputs is acceptable relative to the benefit of
higher quality.
• The task is fuzzy or generative in nature, where a single attempt often underper‐
forms a reranked or filtered approach.
In the supply chain example, an "actor" agent generates reorder plans and a "critic"
evaluates for feasibility (e.g., cost, risk), which is repeated until approval. This subse‐
quent code adds an actor-critic loop after the supervisor:
# Actor Node: Generates candidate plans
def actor_node(state: AgentState):
   history = state["messages"]
   actor_prompt = '''Generate 3 candidate supply chain plans
     as JSON list: [{'plan': 'description', 'tools': [...]}]'''
   response = llm.invoke([SystemMessage(content=actor_prompt)] + history)
   state["candidates"] = json.loads(response.content)
   return state
# Critic Node: Evaluates and selects/iterates
def critic_node(state: AgentState):
   candidates = state["candidates"]
   history = state["messages"]
   critic_prompt = f'''Score candidates {candidates} on scale
    1-10 for feasibility, cost, risk. Select the best if greater than
    8, else request regeneration.'''
   response = llm.invoke([SystemMessage(content=critic_prompt)] + history)
   eval = json.loads(response.content)
   if eval['best_score'] > 8:
       winning_plan = eval['selected']
       # Execute winning plan's tools (similar to specialist execution)
       messages = []
       for tool_info in winning_plan['tools']:
           tc = {'name': tool_info['tool'], 'args': tool_info['args'],
                 'id': 'dummy'}
           fn = next(t for t in all_tools if t.name == tc['name'])
           out = fn.invoke(tc["args"])
           messages.append(ToolMessage(content=str(out), tool_call_id=tc["id"]))
       # Send response
       send_fn.invoke({"message": winning_plan['plan']})
       return {"messages": history + messages}
   else:
       # Iterate: Add feedback to history for actor
       return {"messages": history +
               [AIMessage(content="Regenerate with improvements: " +
                eval['feedback'])]}
def construct_actor_critic_graph():
Multiagent Coordination
|
183
