Software Development and Data Analysis Agents
296
LLMs exhibit a fundamental distinction in their data focus compared to traditional methods. While 
traditional statistical techniques excel at processing structured, tabular data through well-de­
fined mathematical relationships, LLMs demonstrate superior capabilities with unstructured 
text. They can generate code for common data science tasks, particularly boilerplate operations 
involving data manipulation, visualization, and routine statistical analyses. Research on GitHub 
Copilot and similar tools indicates that these assistants can meaningfully accelerate development, 
though the productivity gains observed in independent studies (typically 7–22%) are more modest 
than some vendors claim. BlueOptima’s analysis of over 218,000 developers found productivity 
improvements closer to 4% rather than the 55% claimed in controlled experiments.
Text-to-SQL capabilities represent one of the most promising applications, potentially democra­
tizing data access by allowing non-technical users to query databases in natural language. How­
ever, the performance often drops on the more realistic BIRD benchmark compared to Spider, and 
accuracy remains a key concern, with performance varying significantly based on the complexity 
of the query, the database schema, and the benchmark used. 
LLMs also excel at translating technical findings into accessible narratives for non-technical 
audiences, functioning as a communication bridge in data-driven organizations. While systems 
such as InsightLens demonstrate automated insight organization capabilities, the technology 
shows clear strengths and limitations when generating different types of content. The contrast 
is particularly stark with synthetic data: LLMs effectively create qualitative text samples but 
struggle with structured numerical datasets requiring complex statistical relationships. This 
performance boundary aligns with their core text processing capabilities and highlights where 
traditional statistical methods remain superior. A study published in JAMIA (Evaluating Large 
Language Models for Health-Related Text Classification Tasks with Public Social Media Data, 2024) 
found that “LLMs (specifically GPT-4, but not GPT-3.5) [were] effective for data augmentation in 
social media health text classification tasks but ineffective when used alone to annotate training 
data for supervised models.”
The evidence points toward a future where LLMs and traditional data analysis tools coexist and 
complement each other. The most effective implementations will likely be hybrid systems le­
veraging:
•	
LLMs for natural language interaction, code assistance, text processing, and initial ex­
ploration
•	
Traditional statistical and ML techniques for rigorous analysis of structured data and 
high-stakes prediction tasks
