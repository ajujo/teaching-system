Chapter 6
237
   "Reflect on the answer and provide a feedback whether the answer "
   "is right or wrong. If you think the final answer is correct, reply 
with "
   "the final answer. Only provide critique if you think the answer might 
"
   "be incorrect or there are reasoning flaws. Do not assume anything, "
   "evaluate only the reasoning the student provided and whether there is 
"
   "enough evidence for their answer."
)
class Response(BaseModel):
   """A final response to the user."""
   answer: Optional[str] = Field(
       description="The final answer. It should be empty if critique has 
been provided.",
       default=None,
   )
   critique: Optional[str] = Field(
       description="A critique of the initial answer. If you think it 
might be incorrect, provide an actionable feedback",
       default=None,
   )
reflection_chain = PromptTemplate.from_template(reflection_prompt) | llm.
with_structured_output(Response)
Now we need another research agent that takes not only question and answer options but also the 
previous answer and the feedback. The research agent is tasked with using tools to improve the 
answer and address the critique. We created a simplistic and illustrative example. You can always 
improve it by adding error handling, Pydantic validation (for example, checking that either an 
answer or critique is provided), or handling conflicting or ambiguous feedback (for example, strucÂ­
ture prompts that help the agent prioritize feedback points when there are multiple criticisms).
