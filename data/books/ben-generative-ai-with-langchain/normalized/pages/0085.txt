First Steps with LangChain
58
Here's the image we got:
Figure 2.3: An image generated by Stable Diffusion
Now let's explore how to analyze and understand images using multimodal models.
Image understanding
Image understanding refers to an AI system's ability to interpret and analyze visual information
in ways similar to human visual perception. Unlike traditional computer vision (which focuses
on specific tasks like object detection or facial recognition), modern multimodal models can
perform general reasoning about images, understanding context, relationships, and even implicit
meaning within visual content.
Gemini 2.5 Pro and GPT-4 Vision, among other models, can analyze images and provide detailed
descriptions or answer questions about them.
Using Gemini 1.5 Pro
LangChain handles multimodal input through the same ChatModel interface. It accepts Messages
as an input, and a Message object has a content field. IA content can consist of multiple parts,
and each part can represent a different modality (that allows you to mix different modalities in
your prompt).
