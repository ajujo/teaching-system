First Steps with LangChain
36
Note that the factorial function grows very quickly, so calculating the
factorial of large numbers may exceed the maximum representable value in
Python. In such cases, you might need to use a different approach or a
library that supports arbitrary-precision arithmetic.
Similarly, we could have asked an OpenAI model such as GPT-4 or GPT-4o:
from langchain_openai.chat_models import ChatOpenAI
chat = ChatOpenAI(model_name='gpt-4o')
Reasoning models
Anthropic's Claude 3.7 Sonnet introduces a powerful capability called extended thinking that allows
the model to show its reasoning process before delivering a final answer. This feature represents
a significant advancement in how developers can leverage LLMs for complex reasoning tasks.
Here's how to configure extended thinking through the ChatAnthropic class:
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
# Create a template
template = ChatPromptTemplate.from_messages([
    ("system", "You are an experienced programmer and mathematical
analyst."),
    ("user", "{problem}")
])
# Initialize Claude with extended thinking enabled
chat = ChatAnthropic(
    model_name="claude-3-7-sonnet-20240326",  # Use latest model version
    max_tokens=64_000,                        # Total response length
limit
    thinking={"type": "enabled", "budget_tokens": 15000},  # Allocate
tokens for thinking
)
# Create and run a chain
chain = template | chat
# Complex algorithmic problem
problem = """
