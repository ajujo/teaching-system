Advanced Applications and Multi-Agent Systems
238
Note that we use a less capable LLM for our ReACT agents, just to demonstrate the power of the
reflection approach (otherwise the graph might finish in a single iteration since the agent would
figure out the correct answer with the first attempt):
raw_prompt_template_with_critique = (
   "You tried to answer the exam question and you get feedback from your "
   "professor. Work on improving your answer and incorporating the
feedback. "
   "\nQUESTION:\n{question}\n\nANSWER OPTIONS:\n{options}\n\n"
   "INITIAL ANSWER:\n{answer}\n\nFEEDBACK:\n{feedback}"
)
prompt = ChatPromptTemplate.from_messages(
   [("system", system_prompt),
    ("user", raw_prompt_template_with_critique),
    ("placeholder", "{messages}")
    ]
)
class ReflectionState(ResearchState):
 answer: str
 feedback: str
research_agent_with_critique = create_react_agent(model=llm_small,
tools=research_tools, state_schema=ReflectionState, prompt=prompt)
When defining the state of our graph, we need to keep track of the question and answer options,
the current answer, and the critique. Also note that we track the amount of interaction between
a student and a professor (to avoid infinite cycles between them) and we use a custom reducer for
that (which summarizes old steps and new steps on each run). Let's define the full state, nodes,
and conditional edges:
from typing import Annotated, Literal, TypedDict
from langchain_core.runnables.config import RunnableConfig
from operator import add
from langgraph.graph import StateGraph, START, END
class ReflectionAgentState(TypedDict):
   question: str
