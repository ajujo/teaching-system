# LLM Model Configuration
# This file configures the LLM provider and model settings

llm:
  # Provider: lmstudio, openai, anthropic
  provider: lmstudio

  # LM Studio local server
  base_url: http://localhost:1234/v1

  # Model name (use "default" for LM Studio loaded model)
  model: default

  # Generation parameters
  temperature: 0.7
  max_tokens: 4096

  # Timeout in seconds
  timeout: 120

# Database configuration
database:
  path: db/teaching.db

# Data directory
data_dir: data

# Logging configuration
logging:
  level: INFO
  file: logs/teaching.log
  format: "%(asctime)s | %(levelname)-8s | %(name)s | %(message)s"
  date_format: "%Y-%m-%d %H:%M:%S"

  # Log rotation
  max_size_mb: 10
  backup_count: 5

# Study preferences (defaults)
study:
  default_unit_time: 30  # minutes
  exercises_per_unit: 5
  exam_time_multiplier: 2  # minutes per question
